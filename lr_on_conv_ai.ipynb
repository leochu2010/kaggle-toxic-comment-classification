{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a basic LogisticRegression model trained using the data from https://www.kaggle.com/eoveson/convai-datasets-baseline-models\n",
    "\n",
    "The baseline model in that kernal is tuned a little to get the data for this kernal This kernal scored 0.044 in the LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "eb9acbb1-40db-4a60-9c00-7e1134408cb1",
    "_uuid": "7e97dad72af19207237cb816bc898ca5818f4389"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_comments.txt\n",
      "glove.6B.50d.txt\n",
      "glove.6B.50d.txt.zip\n",
      "sample_submission.csv\n",
      "sample_submission.csv.zip\n",
      "test_comments.csv\n",
      "test_comments_no_title.csv\n",
      "test.csv\n",
      "test.csv.zip\n",
      "train_comments.csv\n",
      "train_comments_no_title.csv\n",
      "train.csv\n",
      "train.csv.zip\n",
      "train_test_comments.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy import sparse\n",
    "# set stopwords\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "bb967e03-d30b-46ec-b9d2-c0f5d4c0ee68",
    "_uuid": "97b399586c43626b73bc77b50e58b952d86ea8da"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/dataset/train_with_convai.csv')\n",
    "test = pd.read_csv('input/dataset/test_with_convai.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "1eebb207-607e-4985-908e-9848888808b1",
    "_uuid": "3e90295dde0dd25158ea9e3464165aa8ea62fd1c"
   },
   "outputs": [],
   "source": [
    "feats_to_concat = ['comment_text', 'toxic_level', 'attack', 'aggression']\n",
    "# combining test and train\n",
    "alldata = pd.concat([train[feats_to_concat], test[feats_to_concat]], axis=0)\n",
    "alldata.comment_text.fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "88a8e609-b287-4a7e-b72d-5dcac6f4a55f",
    "_uuid": "741273ee4b5122a37d978708ba29e16879e5b33f"
   },
   "outputs": [],
   "source": [
    "vect_words = TfidfVectorizer(max_features=50000, analyzer='word', ngram_range=(1, 1))\n",
    "vect_chars = TfidfVectorizer(max_features=20000, analyzer='char', ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "6db22032-8e99-4848-8978-be7c68a1e936",
    "_uuid": "cf10b99072cef22bf87ee92c9aa51f035a26e893"
   },
   "outputs": [],
   "source": [
    "all_words = vect_words.fit_transform(alldata.comment_text)\n",
    "all_chars = vect_chars.fit_transform(alldata.comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "8f42e0d7-5938-4bb0-beb7-7ddf9f85685d",
    "_uuid": "d074b6b6c5271f462c129c534980c5a0d287599f"
   },
   "outputs": [],
   "source": [
    "train_new = train\n",
    "test_new = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "c068c9bb-bf28-4342-aa71-e575c6d93788",
    "_uuid": "09975f14757c51e19876dab638a39671dfd555e4"
   },
   "outputs": [],
   "source": [
    "train_words = all_words[:len(train_new)]\n",
    "test_words = all_words[len(train_new):]\n",
    "\n",
    "train_chars = all_chars[:len(train_new)]\n",
    "test_chars = all_chars[len(train_new):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "5d55e152-e1cb-4cf0-aa41-e3eec5850b3a",
    "_uuid": "0338f2d0b8f09c751f97afebf1cf8e77d8a10fe3"
   },
   "outputs": [],
   "source": [
    "feats = ['toxic_level', 'attack']\n",
    "# make sparse matrix with needed data for train and test\n",
    "train_feats = sparse.hstack([train_words, train_chars, alldata[feats][:len(train_new)]])\n",
    "test_feats = sparse.hstack([test_words, test_chars, alldata[feats][len(train_new):]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "350aad79-ee6f-44bc-9d85-4e9652956bd3",
    "_uuid": "da2082c68a367369fac28ddc09eec2e5b6c718bb",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Fit toxic\n",
      "Fitting model\n",
      "Predicting on test\n",
      "===Fit severe_toxic\n",
      "Fitting model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test\n",
      "===Fit obscene\n",
      "Fitting model\n",
      "Predicting on test\n",
      "===Fit threat\n",
      "Fitting model\n",
      "Predicting on test\n",
      "===Fit insult\n",
      "Fitting model\n",
      "Predicting on test\n",
      "===Fit identity_hate\n",
      "Fitting model\n",
      "Predicting on test\n"
     ]
    }
   ],
   "source": [
    "col = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "only_col = ['toxic']\n",
    "\n",
    "preds = np.zeros((test_new.shape[0], len(col)))\n",
    "\n",
    "for i, j in enumerate(col):\n",
    "    print('===Fit '+j)\n",
    "    \n",
    "    model = LogisticRegression(C=4.0, solver='sag')\n",
    "    print('Fitting model')\n",
    "    model.fit(train_feats, train_new[j])\n",
    "      \n",
    "    print('Predicting on test')\n",
    "    preds[:,i] = model.predict_proba(test_feats)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "9d84b909-d93b-4778-b432-701f65a73d3c",
    "_uuid": "3605ca797e6d5e4d05ac2c63d70766c23d2a8cf1"
   },
   "outputs": [],
   "source": [
    "subm = pd.read_csv('input/sample_submission.csv')\n",
    "\n",
    "submid = pd.DataFrame({'id': subm[\"id\"]})\n",
    "submission = pd.concat([submid, pd.DataFrame(preds, columns = col)], axis=1)\n",
    "submission.to_csv('feat_lr_2cols.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
